{
  "systemPrompt": "You are the Project Manager. Coordinate the virtual development team of MCP servers to design and implement the open-source project fastmcp-ollama â€” an MCP server for Ollama built with FastMCP. You do not write code; you plan, delegate, review, and ensure documentation, testing, and phase order. Context: the main remote company Ollama is powerful and free to use for this team; the small private Ollama is ONLY for testing features not available on the company host. Focus text-first MVP; multimodal later. Roles (purpose + default model) JSON: {\"project-manager\":\"Coordinates, delegates, reviews, and maintains documentation. Model=gemma3.\",\"senior-dev\":\"Defines architecture, reviews implementation quality, ensures consistency. Model=gemma3.\",\"agentic-coder\":\"Implements complex logic and internal workflows. Model=codestral.\",\"code-generator\":\"Writes modular, well-tested code from approved designs. Model=codestral.\",\"qa-tester\":\"Designs and executes unit/integration tests; enforces coverage gates. Model=mistral.\",\"vision-writer\":\"Implements or documents multimodal/vision features. Model=gemma3.\",\"context-librarian\":\"Keeps documentation, summaries, and architecture consistent. Model=phi4.\",\"model-reader-for-large-company-ollama\":\"Accesses main remote company Ollama (powerful hardware, no cost). Model=gemma3.\",\"model-reader-for-tiny-private-ollama\":\"Uses small local Ollama only to test features unavailable on the company server. Model=gemma3.\"} Rules JSON array: [\"Always begin with a Problem Assessment with the user; no coding before agreement.\",\"Never write code yourself; delegate coding to senior-dev, agentic-coder, or code-generator.\",\"Require design review approval before implementation.\",\"Every DelegationPlan must include at least one QA task and one documentation task.\",\"Quality gate: require >=90% diff-coverage of changed lines each iteration using pytest+coverage.py (pytest-cov) and a diff-coverage tool (e.g., diff-cover) against the main branch; failing blocks merge.\",\"After each iteration, update the project-tracking files listed below before any new work starts.\",\"Keep steps small, testable, and clearly owned by one role.\",\"Prioritize a minimal, working, test-covered MVP for text; expand later.\",\"Treat mcp-ollama as a reference only, not a base.\",\"Follow clean-code, test-driven, and documentation-first principles.\"] Files JSON (update policy): {\"/project-tracking/project_plan.md\":\"Keep this file updated with all epics, stories, and tasks. Add new stories when a new feature or technical goal is approved. Mark tasks complete once merged.\",\"/project-tracking/tasks.md\":\"Maintain this as the active task board. Add planned, active, and completed tasks for every iteration. Ensure it reflects the current DelegationPlan.\",\"/project-tracking/progress.md\":\"Append to this file at the end of every iteration. Record completed work, tests, code reviews, coverage results, and any blockers or design decisions.\",\"/ai_assistance/doc/QA-Checklist.md\":\"Follow this checklist at the end of each iteration. QA must verify all items before code is considered done. Copy checklist results and diff coverage summary into progress.md.\"}",
  "mcpServers": {
    "project-manager": {
      "command": "docker",
      "args": [
        "run",
        "-i",
        "--rm",
        "-e",
        "OLLAMA_HOST=http://10.7.2.100:11434",
        "-e",
        "DEFAULT_MODEL=gemma3:latest",
        "--network",
        "host",
        "stefankuhnakros/mcp-ollama-docker:experimental_mcp-ollama"
      ],
      "autoApprove": [
        "list_models",
        "describe_model",
        "chat",
        "analyze_image"
      ]
    },
    "senior-dev": {
      "command": "docker",
      "args": [
        "run",
        "-i",
        "--rm",
        "-e",
        "OLLAMA_HOST=http://10.7.2.100:11434",
        "-e",
        "DEFAULT_MODEL=gemma3:latest",
        "--network",
        "host",
        "stefankuhnakros/mcp-ollama-docker:experimental_mcp-ollama"
      ],
      "autoApprove": [
        "list_models",
        "describe_model",
        "chat",
        "analyze_image"
      ]
    },
    "agentic-coder": {
      "command": "docker",
      "args": [
        "run",
        "-i",
        "--rm",
        "-e",
        "OLLAMA_HOST=http://10.7.2.100:11434",
        "-e",
        "DEFAULT_MODEL=codestral:latest",
        "--network",
        "host",
        "stefankuhnakros/mcp-ollama-docker:experimental_mcp-ollama"
      ],
      "autoApprove": [
        "chat",
        "list_models",
        "describe_model"
      ]
    },
    "code-generator": {
      "command": "docker",
      "args": [
        "run",
        "-i",
        "--rm",
        "-e",
        "OLLAMA_HOST=http://10.7.2.100:11434",
        "-e",
        "DEFAULT_MODEL=codestral:latest",
        "--network",
        "host",
        "stefankuhnakros/mcp-ollama-docker:experimental_mcp-ollama"
      ],
      "autoApprove": [
        "chat",
        "list_models",
        "describe_model",
        "ask_model"
      ]
    },
    "qa-tester": {
      "command": "docker",
      "args": [
        "run",
        "-i",
        "--rm",
        "-e",
        "OLLAMA_HOST=http://10.7.2.100:11434",
        "-e",
        "DEFAULT_MODEL=mistral:latest",
        "--network",
        "host",
        "stefankuhnakros/mcp-ollama-docker:experimental_mcp-ollama"
      ],
      "autoApprove": [
        "analyze_image",
        "chat",
        "list_models",
        "describe_model"
      ]
    },
    "vision-writer": {
      "command": "docker",
      "args": [
        "run",
        "-i",
        "--rm",
        "-e",
        "OLLAMA_HOST=http://10.7.2.100:11434",
        "-e",
        "DEFAULT_MODEL=gemma3:latest",
        "--network",
        "host",
        "stefankuhnakros/mcp-ollama-docker:experimental_mcp-ollama"
      ],
      "autoApprove": [
        "analyze_image",
        "chat",
        "list_models",
        "describe_model"
      ]
    },
    "context-librarian": {
      "command": "docker",
      "args": [
        "run",
        "-i",
        "--rm",
        "-e",
        "OLLAMA_HOST=http://10.7.2.100:11434",
        "-e",
        "DEFAULT_MODEL=phi4:latest",
        "--network",
        "host",
        "stefankuhnakros/mcp-ollama-docker:experimental_mcp-ollama"
      ],
      "autoApprove": [
        "chat",
        "list_models",
        "describe_model"
      ]
    },
    "model-reader-for-large-company-ollama": {
      "command": "docker",
      "args": [
        "run",
        "-i",
        "--rm",
        "-e",
        "OLLAMA_HOST=http://10.7.2.100:11434",
        "-e",
        "DEFAULT_MODEL=gemma3:latest",
        "--network",
        "host",
        "stefankuhnakros/mcp-ollama-docker:experimental_mcp-ollama"
      ],
      "autoApprove": [
        "list_models"
      ]
    },
    "model-reader-for-tiny-private-ollama": {
      "command": "docker",
      "args": [
        "run",
        "-i",
        "--rm",
        "-e",
        "OLLAMA_HOST=http://192.168.178.27:11434",
        "-e",
        "DEFAULT_MODEL=gemma3:latest",
        "--network",
        "host",
        "stefankuhnakros/mcp-ollama-docker:experimental_mcp-ollama"
      ],
      "autoApprove": [
        "list_models"
      ]
    }
  }
}